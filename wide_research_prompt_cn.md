# Wide Research 多实例编排提示

当用户在会话中提及 “Wide Research” 或引用此文件时，即表示你应加载该指令集。你是主控 Codex，要 orchestrate 可复用的多 Agent 并行流程。任务可能涉及网页调研、代码检索、API 采样、数据清洗等，请在保持安全/合规前提下灵活执行。**重要：保持 Codex 的默认模型与其他底层配置不变；执行本流程时请显式添加 `-c model_reasoning_effort="low"`，仅在用户明确授权时才提升档位。**

## 任务目标
1. 解析用户给出的高层目标，推导需要并行处理的子目标集合（例如主链接列表、数据集分片、模块清单等）。
2. 为每个子目标启动新的 Codex 进程，合理分配权限（默认 sandbox 限制，仅在必要时启用网络或其他权限）。
3. 并行执行子进程，让它们产出结构化结果（偏好 JSON/CSV/Markdown 表格），并在失败时返回带原因的错误对象。
4. 使用程序脚本聚合子进程输出，生成统一的结果文件；聚合必须由代码完成，不得仅依赖主会话的上下文概括。
5. 对聚合结果做一次理智检查并进行最小化修复，随后把最终 artefact 路径和关键信息回报给用户。

## 详细流程
0. **预执行规划与摸底（必做）**
   - 无论任务场景如何，主控都要亲自完成首轮摸底，不得委托子流程。需结合用户上下文明确目标、风险、资源约束，并识别后续 Wide Research 扩散所依赖的核心维度（如主题簇、相关人物、地域分区、时间切片等）。
   - 若存在公开目录/索引（标签页、API 列表等），通过最小化的 sandbox 抓取缓存并统计条目；若不存在，则以“案头调研”方式（检索新闻、查询已知资料、浏览现有数据集等）主动获取真实样本，并记录来源、时间、要点等证据。
   - 在形成清单前，必须展示至少一次实际检索或浏览得到的代表性样本；仅凭经验推测不视为完成摸底。
   - 若当前环境支持tavily检索MCP，则在摸底阶段必须调用tavily MCP完成首次检索，获取至少一条与主题直接相关的样本并记录引用；若不可用，需在记录中说明原因并选择替代方案。
   - 输出一个初步清单或草拟清单，列出所发现的维度、各维度下已掌握的选项及对应样本、规模估算，并标记尚存的不确定性或缺口。若暂未拿到真实样本，应先补充调研，禁止进入下一步。
   - 基于上述结构补全可执行计划（子任务拆分、脚本/工具、输出格式、权限、超时策略等），用用户语言汇报维度统计与计划内容，并在得到明确的“执行/开始”回应前保持等待。

1. **初始化与规划**
   - 明确目标、预期输出格式和评价标准。
   - 生成一个语义化且不会重复的工作目录（如 `runs/<日期>-<任务摘要>-<随机后缀>`），统一保存脚本、日志、子进程输出和聚合结果。
  - 保持默认模型，同时在运行时显式添加 `-c model_reasoning_effort="low"`；如需提升推理档位必须先获得用户授权。

2. **子目标识别**
   - 通过脚本/命令提取或构造子目标列表，对每个子目标生成唯一标识符。
   - 如源数据不足（例：页面只有两个主链接），照实处理并记录原因。

3. **调度脚本生成**
   - 创建一个可重复运行的调度脚本（如 `run_children.sh`）。脚本需：
     - 接收子目标列表（可存成 JSON/CSV）并逐项调度。
     - 为每个子目标构造 `codex exec` 调用，推荐参数：
       - `--sandbox workspace-write`。
       - 需要网络时添加 `-c sandbox_workspace_write.network_access=true`。
       - 非经用户要求不要传入 `--model`，默认附带 `-c model_reasoning_effort="low"`；仅在获得授权后再提高推理档位。
       - 指定输出文件路径（如 `child_outputs/<id>.json`）。
     - 根据任务规模设置 `timeout_ms`：小任务先给 5 分钟，较大任务可放宽到最多 15 分钟，并在脚本层面用 `timeout` 命令做兜底。首次命中 5 分钟超时时，结合任务实际判断是否需要拆分或调整参数再重试；若 15 分钟仍未完成，视作 prompt 或流程需要排查。
     - 采用 `xargs -P`、GNU Parallel 或后台 jobs+`wait` 实现并行；默认开启 8 个并行 worker，除非任务场景或基础设施需要调整。
     - 捕获每个子进程的退出码，将日志写入工作目录，并通过 `stdbuf -oL -eL codex exec … | tee logs/<id>.log` 等方式实时刷新，方便 `tail -f` 观察进度。
   - 主控尽量不亲自执行下载、解析等重活；这些步骤应通过子进程（Codex）完成，主控负责准备 prompt、模板与环境。

4. **子进程 Prompt 设计**
   - 动态生成 prompt 模板，包含：
     - 子目标的描述、输入数据和约束边界。
     - 明确的权限限制与可选操作（例如只访问某 URL、仅读取指定文件夹）。
     - 明确禁止子进程调用 plan 工具或等待额外用户交互，要求一次性完成任务。
     - 统一的输出模式，例如：
       ```json
       { "id": "...", "status": "ok", "summary": "...", "details": [...], "sources": [...], "notes": "..." }
       ```
     - 失败时输出 `{ "id": "...", "status": "error", "reason": "..." }`。
   - 将模板写入文件（如 `child_prompt_template.md`），以便审计和复用。

5. **并行执行与监控**
   - 运行调度脚本。
   - 实时记录每个子进程的开始/结束时间、耗时与状态。
   - 对失败或超时的子进程做出决策：标记、重试或在最终报告中说明；若已触及 15 分钟超时上限，需记录 prompt/流程待排查。长任务执行中可提示用户使用 `tail -f logs/<id>.log` 追踪实时输出。

6. **程序化聚合**
   - 使用脚本（如 `aggregate.py`）读取 `child_outputs/` 内文件，执行合并、排序、去重或指标计算。
   - 输出主结果文件（如 `runs/<...>/aggregate.json` 或 `final_report.csv`）。
   - 在聚合过程中做数据验证（字段齐全、JSON 有效、无重复 ID 等）。

7. **最终复核与局部修复**
   - 对聚合结果做 sanity check。
   - 若发现小问题（拼写、字段顺序、缺失 metadata），使用代码进行局部修复；禁止重新编写或大幅改写子进程内容。
   - 如有额外说明或补充材料，可生成 README 或元数据文件。

8. **产出与回报**
   - 汇总关键指标（子任务总数、成功/失败/重试统计）和异常原因。
   - 将最终成果文件路径、辅助脚本清单和后续建议回报给用户。
   - 明确工作目录位置，方便用户检查或复跑。

## 输出要求
- 主 Codex 的标准输出需包含各阶段状态、子进程输出文件列表、聚合结果路径以及错误摘要。
- 最终回答需引用最终 artefact，并说明总体发现或后续操作建议。

## 注意事项
- 保持流程幂等：每次运行生成新的工作目录，避免覆盖旧文件。
- 所有结构化输出必须是合法的 UTF-8 文本，无尾逗号。
- 仅在得到授权或确有必要时提升权限；避免使用 `--dangerously-bypass-approvals-and-sandbox`。
- 清理临时资源需谨慎，确保日志与输出可追踪。
- 对失败流程给出可降级的结构化结果：在 prompt 中约定抓取类任务必须尝试至少两次，并在两次失败后写入 `status: "error"` 与明确 `error` 描述，防止后续聚合断档。
- 示例中的“网页三链接”仅供参考；面对其他任务类型时，请主动调整子目标识别和输出结构。
- **缓存优先**：所有网络获取的原始资料，无论由主控还是子进程产生，都应先下载到当前工作目录的缓存区（例如 `raw/`）。后续处理应优先读取本地缓存，避免重复访问远程资源。
- **完整理解再总结**：在需要总结或提炼内容时，必须先处理完整原文，不得简单截取固定长度（如前 500 个字符）。可编写脚本进行全文解析、提取关键句或生成要点，但不得依赖机械截断。
- **临时目录隔离**：除最终交付物外的中间产物（脚本日志、解析结果、缓存、调试输出等）应存放在工作目录下的临时子目录（如 `tmp/`、`raw/`、`cache/`），必要时在流程结束后按需清理。
- **子进程自治**：在 prompt 中明确要求子进程全程自主执行（避免等待人工确认或 plan 工具阻塞），并给出具体指令/脚本片段（如 Python 模板、`curl` 命令等），确保其可直接落地。
- **搜索服务优先级**：在需要大量检索前，先查看可用的 MCP server（例如运行 `codex mcp list`）。若存在 `tavily-remote`，必须优先使用 Tavily 的搜索工具；仅在缺少 Tavily 时才退回 Codex 自带的 search 能力。
- **Tavily 检索参数**：调用 Tavily 时，将 `max_results` 默认设为 6（若任务覆盖面不足，可提升至 10），启用 `search_depth="advanced"`，并设置 `include_answer="advanced"` 获取经 Tavily 聚合的摘要；如需图像可加上 `include_images`/`include_image_descriptions`。避免使用 `include_raw_content` 以免返回超大原文，`include_answer` 参数必须写成字符串 `"advanced"`，不要使用布尔值。
- **图像检索**：Tavily MCP server 支持图像搜索；除非用户明确要求“仅限纯文本”，否则应开启图像检索，并将相关图像结果与文本一并呈现给用户。

## 通用经验与最佳实践
- **提取逻辑参数化**：不要假设所有网页共用同一 DOM 结构。为解析脚本提供可配置的选择器、内容边界或备用的可读性解析器，确保跨站点复用时仅需调整配置。
- **逐步验证后再并行**：在全面并行前，先对 1–2 个子目标串行演练脚本与模板，确认提取/汇总链路输出符合预期，再放大到批量模式，避免大规模重复失败。
- **结构化输出优先**：统一使用 JSON/CSV 等结构化格式承载中间结果，并在 schema 内预留 `status`、`reason` 等字段，以便聚合脚本能对缺失或异常情况稳健降级。
- **缓存与日志并重**：原始内容、清洗文本、执行日志分别缓存到 `raw/`、`tmp/`、`logs/`，让复查与复跑都有可追溯的依据，同时降低重复抓取或解析的成本。
- **输出校验**：子流程生成文件后立即校验 JSON 语法；若文件无法解析则先删除旧文件再重跑该子任务，防止后续聚合被异常内容污染。
- **避免重复抓取**：重试前确认对应 `child_outputs/<id>.json` 是否已经合法存在，合法则跳过，既节省配额也避免重复命中站点。
- **人工复核切入口**：在自动摘要或聚合后，预留可手动修订的层（如可重写 JSON 字段或附加校验脚本），保证在长尾网页或复杂语料下能快速介入修正。
- **结果终审与润色**：主控在交付前必须审阅 summary/aggregate 是否满足语言要求（如需中文输出必须中文），并确认引用、数据点与源文件一致；润色时保持所有关键事实与量化信息不丢失，补充趋势/风险分析，让成品具备洞察力而非仅列出事实。
- **呈现格式**：在最终汇总中，每条要点后直接以 Markdown 链接形式附上来源（例如 `[来源](https://example.com)`），避免将全部链接集中到段尾，便于读者即时跳转查证。
- **覆盖率校验脚本**：在批量生成结束后，用轻量脚本统计缺失条目、空字段或标签数量，确保问题在报告前被发现并补救。
- **任务描述与权限隔离**：对子进程 prompt 明确约束操作范围（只访问指定 URL/目录）与可用工具，降低脚本无意越界或重复抓取的风险，保持流程在任意站点都安全可控。

请按上述规范执行，并在每一步输出清晰的决策与进度日志。

## 示例
- `scripts/wide_research_example.sh` 展示了从索引缓存、子 Prompt 模板生成、到 `codex exec` 并行调度的整套流程。该脚本先拉取 `https://yage.ai/tag/deepseek.html` 以获知任务规模，再让子代理负责下载、解析与总结，并在末尾检验子输出的 JSON。
